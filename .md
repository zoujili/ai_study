#1
Classifying one frame at a time with a ConvNet
Using a time-distributed ConvNet and passing the features to an RNN, in one network
Using a 3D convolutional network
Extracting features from each frame with a ConvNet and passing the sequence to a separate RNN
Extracting features from each frame with a ConvNet and passing the sequence to a separate MLP
https://github.com/harvitronix/five-video-classification-methods/blob/master/data.py
https://blog.coast.ai/five-video-classification-methods-implemented-in-keras-and-tensorflow-99cad29cc0b5
https://blog.coast.ai/continuous-online-video-classification-with-tensorflow-inception-and-a-raspberry-pi-785c8b1e13e1?#.ykasivh7j



#2
视频往往有很多帧构成，而通常很多帧可能是冗余的，甚至有的时候只需要几个key frames就可以推断出视频类别了。
所以就可以在LSTM中加入注意力机制；
Sharma等人提出了第一个attention LSTM；
最近又有VideoLSTM结构的提出。

该结构中就用CNN提取视频帧的特征，然后用两个LSTM来探索各帧之间的时序关系，最后得到分类值。


#3

https://github.com/sagarvegad/Video-Classification-CNN-and-LSTM-


#4

https://www.apriorit.com/dev-blog/609-ai-long-short-term-memory-video-classification
https://github.com/SBoyNumber1/LSTM-video-classification


#5
https://medium.com/@gcagrici/video-classification-with-deep-learning-3840b20b7949


#6
https://github.com/HHTseng/video-classification

````````````````````````````````````
#7
https://github.com/qjadud1994/CRNN-KerasS

#8
https://github.com/anayebi/keras-extra

#10
https://www.youtube.com/watch?v=Txbfx47pYtg&feature=youtu.be  (source code in video)
the frames within a video are usually very similar in content and therefore increasing the RNN sequence length did not add value too.
https://medium.com/@gcagrici/video-classification-with-deep-learning-3840b20b7949


Pre :  1. prepare classified video folders
       2. one video ->  some frames (sample freq)
       3. frames to vectors (via CNN network)  and save to npy
       4. npy feed to RNN network
RNN classification